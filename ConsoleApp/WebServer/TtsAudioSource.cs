using SIPSorceryMedia.Abstractions;
using Microsoft.Extensions.Logging;
using System.Speech.Synthesis;
using System.Speech.AudioFormat;

namespace ConsoleApp.WebServer
{
    /// <summary>
    /// –ê—É–¥–∏–æ –∏—Å—Ç–æ—á–Ω–∏–∫ —Å —Å–∏–Ω—Ç–µ–∑–æ–º —Ä–µ—á–∏ (TTS) –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–¥–∞—á–∏
    /// –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π Windows Speech Synthesizer
    /// </summary>
    public class TtsAudioSource : IAudioSource, IDisposable
    {
        private readonly ILogger<TtsAudioSource> _logger;
        private bool _isStarted = false;
        private bool _isPaused = false;
        private Timer? _sendTimer;
        private SpeechSynthesizer? _synthesizer;

        // –ë—É—Ñ–µ—Ä –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
        private Queue<byte[]> _audioBuffer = new Queue<byte[]>();
        private readonly object _bufferLock = new object();

        // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–¥–∏–æ
        private int _sampleIndex = 0;
        private readonly int _sampleRate = 8000;

        // –¢–µ—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–∑—ã
        private readonly string[] _testPhrases = {
            "–ü—Ä–∏–≤–µ—Ç, —ç—Ç–æ —Ç–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–¥–∞—á–∏ –≥–æ–ª–æ—Å–∞",
            "–ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ç–∫–æ—Å—Ç—å –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤",
            "–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–µ–¥–∞—á—É —Ä–µ—á–∏ —á–µ—Ä–µ–∑ SIP –ø—Ä–æ—Ç–æ–∫–æ–ª",
            "–ö–∞—á–µ—Å—Ç–≤–æ –∑–≤—É–∫–∞ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–µ–∑ –∏—Å–∫–∞–∂–µ–Ω–∏–π"
        };
        private int _currentPhraseIndex = 0;

        public TtsAudioSource(ILogger<TtsAudioSource> logger)
        {
            _logger = logger;
            InitializeTts();
        }

        public event EncodedSampleDelegate? OnAudioSourceEncodedSample;
        public event SourceErrorDelegate? OnAudioSourceError;
        public event Action<EncodedAudioFrame>? OnAudioSourceEncodedFrameReady;
        public event RawAudioSampleDelegate? OnAudioSourceRawSample;

        /// <summary>
        /// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç TTS —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä
        /// </summary>
        private void InitializeTts()
        {
            try
            {
                _synthesizer = new SpeechSynthesizer();

                // –í—ã–±–∏—Ä–∞–µ–º —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                var russianVoice = _synthesizer.GetInstalledVoices()
                    .FirstOrDefault(v => v.VoiceInfo.Culture.Name.StartsWith("ru"));

                if (russianVoice != null)
                {
                    _synthesizer.SelectVoice(russianVoice.VoiceInfo.Name);
                    _logger.LogInformation("TTS: –≤—ã–±—Ä–∞–Ω —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å - {VoiceName}", russianVoice.VoiceInfo.Name);
                }
                else
                {
                    _logger.LogWarning("TTS: —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–æ–ª–æ—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é");
                }

                // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –∏ –≥—Ä–æ–º–∫–æ—Å—Ç—å
                _synthesizer.Rate = 0; // –ù–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å
                _synthesizer.Volume = 80; // 80% –≥—Ä–æ–º–∫–æ—Å—Ç–∏

                _logger.LogInformation("TTS —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω");
            }
            catch (Exception ex)
            {
                _logger.LogError($"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ TTS: {ex.Message}");
            }
        }

        /// <summary>
        /// –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∞—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç—ã - —Ç–æ–ª—å–∫–æ G.711
        /// </summary>
        public List<AudioFormat> GetAudioSourceFormats()
        {
            return new List<AudioFormat>
            {
                new AudioFormat(SDPWellKnownMediaFormatsEnum.PCMA),    // G.711 A-law
                new AudioFormat(SDPWellKnownMediaFormatsEnum.PCMU),    // G.711 Œº-law
            };
        }

        private static bool _useAlaw = false;

        public void SetAudioSourceFormat(AudioFormat audioFormat)
        {
            _useAlaw = audioFormat.FormatID == (int)SDPWellKnownMediaFormatsEnum.PCMA;
            string formatName = _useAlaw ? "A-law" : "Œº-law";
            _logger.LogInformation("TTS: —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–æ—Ä–º–∞—Ç G.711 {FormatName}", formatName);
        }

        public Task StartAudio()
        {
            if (_isStarted)
            {
                _logger.LogWarning("TtsAudioSource: —É–∂–µ –∑–∞–ø—É—â–µ–Ω, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—ã–π —Å—Ç–∞—Ä—Ç");
                return Task.CompletedTask;
            }

            _isStarted = true;
            _isPaused = false;
            _logger.LogInformation("TtsAudioSource: –∑–∞–ø—É—Å–∫ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏");
            _logger.LogInformation("  –ü–æ–¥–ø–∏—Å—á–∏–∫–∏ OnAudioSourceEncodedSample: {HasSubscribers}", OnAudioSourceEncodedSample != null);

            // –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é —Ñ—Ä–∞–∑—É
            SynthesizeNextPhrase();

            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –∫–∞–¥—Ä—ã –∫–∞–∂–¥—ã–µ 20ms
            _sendTimer = new Timer(SendAudioFrame, null, 0, 20);
            _logger.LogInformation("TtsAudioSource: —Ç–∞–π–º–µ—Ä –∑–∞–ø—É—â–µ–Ω (–∏–Ω—Ç–µ—Ä–≤–∞–ª 20ms)");
            return Task.CompletedTask;
        }

        /// <summary>
        /// –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Å–ª–µ–¥—É—é—â—É—é —Ñ—Ä–∞–∑—É –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ –±—É—Ñ–µ—Ä
        /// </summary>
        private void SynthesizeNextPhrase()
        {
            if (_synthesizer == null) return;

            try
            {
                string phrase = _testPhrases[_currentPhraseIndex];
                _currentPhraseIndex = (_currentPhraseIndex + 1) % _testPhrases.Length;

                Console.WriteLine($"üé§ TTS —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç: \"{phrase}\"");
                _logger.LogInformation("TTS —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ñ—Ä–∞–∑—É: {Phrase}", phrase);

                // –°–æ–∑–¥–∞–µ–º –ø–æ—Ç–æ–∫ –≤ –ø–∞–º—è—Ç–∏ –¥–ª—è –∑–∞–ø–∏—Å–∏ WAV
                using var memoryStream = new MemoryStream();

                // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç: 8kHz, 16-bit, mono –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è G.711
                var formatInfo = new System.Speech.AudioFormat.SpeechAudioFormatInfo(8000, AudioBitsPerSample.Sixteen, AudioChannel.Mono);
                _synthesizer.SetOutputToAudioStream(memoryStream, formatInfo);

                // –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å
                _synthesizer.Speak(phrase);

                // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º WAV –≤ PCM –∏ –∑–∞—Ç–µ–º –≤ G.711
                var wavData = memoryStream.ToArray();
                ConvertWavToG711Buffer(wavData);

                _logger.LogInformation("TTS: —Ñ—Ä–∞–∑–∞ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–∞, –¥–æ–±–∞–≤–ª–µ–Ω–æ {Frames} –∫–∞–¥—Ä–æ–≤ –≤ –±—É—Ñ–µ—Ä", _audioBuffer.Count);
            }
            catch (Exception ex)
            {
                _logger.LogError($"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {ex.Message}");
                Console.WriteLine($"‚úó –û—à–∏–±–∫–∞ TTS: {ex.Message}");
            }
        }

        /// <summary>
        /// –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç WAV –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä G.711 –∫–∞–¥—Ä–æ–≤
        /// </summary>
        private void ConvertWavToG711Buffer(byte[] wavData)
        {
            // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º WAV –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–æ–±—ã—á–Ω–æ 44 –±–∞–π—Ç–∞)
            int dataOffset = 44;
            if (wavData.Length <= dataOffset) return;

            var pcmData = new ArraySegment<byte>(wavData, dataOffset, wavData.Length - dataOffset);

            lock (_bufferLock)
            {
                // –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∫–∞–¥—Ä—ã –ø–æ 160 —Å–µ–º–ø–ª–æ–≤ (320 –±–∞–π—Ç PCM = 160 –±–∞–π—Ç G.711)
                const int frameSize = 320; // 160 —Å–µ–º–ø–ª–æ–≤ * 2 –±–∞–π—Ç–∞ –Ω–∞ —Å–µ–º–ø–ª
                const int g711FrameSize = 160;

                for (int i = 0; i < pcmData.Count; i += frameSize)
                {
                    int bytesToProcess = Math.Min(frameSize, pcmData.Count - i);
                    if (bytesToProcess < frameSize) break; // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–ø–æ–ª–Ω—ã–µ –∫–∞–¥—Ä—ã

                    var g711Frame = new byte[g711FrameSize];

                    // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PCM 16-bit –≤ G.711
                    for (int j = 0; j < g711FrameSize; j++)
                    {
                        int pcmIndex = i + (j * 2);
                        if (pcmIndex + 1 < pcmData.Count)
                        {
                            // –ß–∏—Ç–∞–µ–º 16-bit little-endian —Å–µ–º–ø–ª
                            short pcmSample = (short)(pcmData[pcmIndex] | (pcmData[pcmIndex + 1] << 8));
                            g711Frame[j] = _useAlaw ? LinearToALaw(pcmSample) : LinearToMuLaw(pcmSample);
                        }
                    }

                    _audioBuffer.Enqueue(g711Frame);
                }
            }
        }

        /// <summary>
        /// –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞—É–¥–∏–æ –∫–∞–¥—Ä –∏–∑ –±—É—Ñ–µ—Ä–∞
        /// </summary>
        private void SendAudioFrame(object? state)
        {
            if (!_isStarted || _isPaused)
            {
                return;
            }

            if (OnAudioSourceEncodedSample == null)
            {
                if (_sampleIndex < 1600)
                {
                    Console.WriteLine($"‚ö† TtsAudioSource: –Ω–µ—Ç –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –Ω–∞ OnAudioSourceEncodedSample (–∫–∞–¥—Ä {_sampleIndex / 160})");
                }
                return;
            }

            byte[]? frame = null;
            lock (_bufferLock)
            {
                if (_audioBuffer.Count > 0)
                {
                    frame = _audioBuffer.Dequeue();
                }
            }

            if (frame != null)
            {
                try
                {
                    OnAudioSourceEncodedSample?.Invoke(8000, frame);

                    // –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ –∫–∞–¥—Ä—ã
                    if (_sampleIndex < 3200 || _sampleIndex % (8000 * 5) == 0)
                    {
                        Console.WriteLine($"üéµ TtsAudioSource: –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∫–∞–¥—Ä #{_sampleIndex / 160}, {(double)_sampleIndex / 8000:F1}—Å");
                    }
                }
                catch (ArgumentException ex) when (ex.Message.Contains("An empty destination was specified"))
                {
                    if (_sampleIndex < 1600)
                    {
                        Console.WriteLine($"‚ö† TtsAudioSource: RTP destination –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–∑–≤–æ–Ω–æ–∫ –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω) - –∫–∞–¥—Ä {_sampleIndex / 160}");
                    }
                }
                catch (Exception ex)
                {
                    _logger.LogError($"TtsAudioSource: –æ—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫–∞–¥—Ä–∞: {ex.Message}");
                }
            }
            else
            {
                // –ë—É—Ñ–µ—Ä –ø—É—Å—Ç - —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Å–ª–µ–¥—É—é—â—É—é —Ñ—Ä–∞–∑—É
                if (_audioBuffer.Count == 0)
                {
                    SynthesizeNextPhrase();
                }
            }

            _sampleIndex += 160;
        }

        public void StopAudio()
        {
            if (!_isStarted) return;

            _isStarted = false;
            _sendTimer?.Dispose();
            _sendTimer = null;

            lock (_bufferLock)
            {
                _audioBuffer.Clear();
            }

            _logger.LogInformation("TtsAudioSource: –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω");
        }

        public Task CloseAudio()
        {
            StopAudio();
            return Task.CompletedTask;
        }

        public Task PauseAudio()
        {
            _isPaused = true;
            _logger.LogInformation("TtsAudioSource: –ø–∞—É–∑–∞");
            return Task.CompletedTask;
        }

        public Task ResumeAudio()
        {
            _isPaused = false;
            _logger.LogInformation("TtsAudioSource: –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ");
            return Task.CompletedTask;
        }

        public bool IsAudioSourcePaused() => _isPaused;
        public bool HasEncodedAudioSubscribers() => OnAudioSourceEncodedSample != null;
        public void RestrictFormats(Func<AudioFormat, bool> filter) { }
        public void ExternalAudioSourceRawSample(AudioSamplingRatesEnum samplingRate, uint durationMilliseconds, short[] samples) { }

        /// <summary>
        /// –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ G.711 Œº-law
        /// </summary>
        private static byte LinearToMuLaw(short sample)
        {
            const short BIAS = 132;
            const short CLIP = 32635;

            int sign = (sample >> 8) & 0x80;
            if (sign != 0) sample = (short)-sample;
            if (sample > CLIP) sample = CLIP;

            sample = (short)(sample + BIAS);
            int exponent = 7;
            for (int mask = 0x4000; mask != 0x80; mask >>= 1, exponent--)
            {
                if ((sample & mask) != 0) break;
            }

            int mantissa = (sample >> (exponent + 3)) & 0x0F;
            int result = ((exponent << 4) | mantissa);
            return (byte)(~result ^ sign);
        }

        /// <summary>
        /// –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ G.711 A-law
        /// </summary>
        private static byte LinearToALaw(short sample)
        {
            const short CLIP = 32635;

            bool isNegative = sample < 0;
            if (isNegative) sample = (short)-sample;
            if (sample > CLIP) sample = CLIP;

            byte result;
            if (sample < 256)
            {
                result = (byte)(sample >> 4);
            }
            else
            {
                int exponent = 7;
                for (int testBit = 0x4000; testBit > 0; testBit >>= 1)
                {
                    if ((sample & testBit) != 0) break;
                    exponent--;
                }

                int mantissa = (sample >> (exponent + 3)) & 0x0F;
                result = (byte)(((exponent - 1) << 4) | mantissa);
            }

            if (!isNegative) result |= 0x80;
            return (byte)(result ^ 0x55);
        }

        public void Dispose()
        {
            StopAudio();
            _synthesizer?.Dispose();
        }
    }
}